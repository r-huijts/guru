#!/usr/bin/env python3
"""
ü§ó Upload Spiritual AI to Hugging Face Hub
==========================================

Upload your fine-tuned spiritual wisdom model to Hugging Face Hub
for easy access and integration with Ollama.
"""

import os
import json
from pathlib import Path
from huggingface_hub import HfApi, create_repo, upload_folder
import logging

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def create_model_card(model_name: str, username: str) -> str:
    """Create a comprehensive model card for the spiritual AI."""
    
    model_card = f"""---
license: llama3.2
base_model: unsloth/Llama-3.2-3B-Instruct-bnb-4bit
tags:
- spiritual-wisdom
- meditation
- consciousness
- fine-tuned
- unsloth
- llama-3.2
language:
- en
pipeline_tag: text-generation
---

# üßò‚Äç‚ôÇÔ∏è Spiritual Wisdom AI - Llama 3.2 3B

## Model Description

This is a fine-tuned Llama 3.2 3B model specialized in spiritual wisdom, meditation guidance, and consciousness exploration. The model has been trained on a curated dataset of spiritual teachings and wisdom traditions.

## üåü Model Performance

**Evaluation Results (A+ Grade - 0.95/1.0 Overall Quality):**
- **Concept Understanding**: 1.00/1.0 (Perfect)
- **Practical Guidance**: 0.94/1.0 (Excellent)
- **Philosophical Depth**: 0.94/1.0 (Excellent)  
- **Teaching Scenarios**: 0.81/1.0 (Very Good)

## üéØ Capabilities

The model excels at:
- Explaining spiritual concepts (consciousness, meditation, enlightenment)
- Providing practical guidance for inner peace and mindfulness
- Offering philosophical insights on life's deeper questions
- Teaching meditation and spiritual practices
- Helping with emotional and spiritual challenges

## üöÄ Usage

### With Transformers
```python
from transformers import AutoModelForCausalLM, AutoTokenizer

model = AutoModelForCausalLM.from_pretrained("{username}/{model_name}")
tokenizer = AutoTokenizer.from_pretrained("{username}/{model_name}")

# Format your prompt
prompt = '''<|begin_of_text|><|start_header_id|>user<|end_header_id|>

What is the nature of consciousness?<|eot_id|><|start_header_id|>assistant<|end_header_id|>

'''

inputs = tokenizer(prompt, return_tensors="pt")
outputs = model.generate(**inputs, max_new_tokens=200, temperature=0.8)
response = tokenizer.decode(outputs[0], skip_special_tokens=True)
```

### With Ollama
```bash
# Import the model
ollama pull {username}/{model_name}

# Chat with the model
ollama run {username}/{model_name} "What is meditation?"
```

## üìä Training Details

- **Base Model**: unsloth/Llama-3.2-3B-Instruct-bnb-4bit
- **Training Framework**: Unsloth (2x faster training)
- **Training Time**: 4.5 minutes on RTX 4090
- **Dataset Size**: 520 spiritual wisdom examples
- **LoRA Configuration**: r=16, alpha=16, dropout=0
- **Training Loss Improvement**: 32.1% (3.294 ‚Üí 2.236)

## üßò‚Äç‚ôÇÔ∏è Example Conversations

**User**: "I'm feeling anxious and overwhelmed. How can I find peace?"

**AI**: "When anxiety overwhelms you, remember that peace is not the absence of storms, but finding calm within them. Begin with your breath - it's always available as an anchor to the present moment. Take three deep breaths, feeling your body soften with each exhale..."

**User**: "What is the difference between mind and consciousness?"

**AI**: "The mind is like waves on the ocean - thoughts, emotions, and mental activities that come and go. Consciousness is the ocean itself - the aware presence that observes these waves without being disturbed by them..."

## ‚ö†Ô∏è Limitations

- Specialized for spiritual/philosophical topics
- May not perform well on technical or factual queries outside its domain
- Responses reflect training data perspectives on spirituality
- Should not replace professional mental health or medical advice

## üôè Ethical Considerations

This model is designed to offer wisdom and guidance in the spirit of compassion and understanding. It draws from various spiritual traditions while respecting their diversity. Users should approach the guidance with discernment and seek qualified teachers for serious spiritual practice.

## üìú License

This model is released under the Llama 3.2 license. Please review the license terms before use.

## üîó Links

- **Training Code**: Available in the model repository
- **Evaluation Scripts**: Comprehensive testing suite included
- **Base Model**: [unsloth/Llama-3.2-3B-Instruct-bnb-4bit](https://huggingface.co/unsloth/Llama-3.2-3B-Instruct-bnb-4bit)

---

*May this AI serve as a helpful companion on your journey of wisdom and understanding.* üåü
"""
    
    return model_card


def upload_model_to_hf(
    model_path: str = "models/spiritual-wisdom-llama",
    repo_name: str = "spiritual-wisdom-llama-3b",
    username: str = None,
    private: bool = False
):
    """Upload the fine-tuned model to Hugging Face Hub."""
    
    if not username:
        username = input("Enter your Hugging Face username: ").strip()
    
    if not username:
        raise ValueError("Username is required!")
    
    model_path = Path(model_path)
    if not model_path.exists():
        raise FileNotFoundError(f"Model not found at {model_path}")
    
    repo_id = f"{username}/{repo_name}"
    
    logger.info(f"üöÄ Uploading model to Hugging Face: {repo_id}")
    
    # Initialize HF API
    api = HfApi()
    
    try:
        # Create repository
        logger.info("üìÅ Creating repository...")
        create_repo(
            repo_id=repo_id,
            private=private,
            exist_ok=True
        )
        
        # Create model card
        logger.info("üìù Creating model card...")
        model_card_content = create_model_card(repo_name, username)
        
        # Save model card to model directory
        readme_path = model_path / "README.md"
        with open(readme_path, 'w') as f:
            f.write(model_card_content)
        
        # Upload the entire model folder
        logger.info("‚¨ÜÔ∏è Uploading model files...")
        upload_folder(
            folder_path=str(model_path),
            repo_id=repo_id,
            commit_message="Upload fine-tuned spiritual wisdom Llama 3.2 model"
        )
        
        logger.info("‚úÖ Model uploaded successfully!")
        logger.info(f"üîó Model URL: https://huggingface.co/{repo_id}")
        
        return repo_id
        
    except Exception as e:
        logger.error(f"‚ùå Upload failed: {e}")
        raise


def create_ollama_modelfile(repo_id: str, model_name: str = "spiritual-ai"):
    """Create an Ollama Modelfile for the uploaded model."""
    
    modelfile_content = f"""FROM {repo_id}

TEMPLATE \"\"\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>

{{{{ prompt }}}}<|eot_id|><|start_header_id|>assistant<|end_header_id|>

\"\"\"

PARAMETER temperature 0.8
PARAMETER top_p 0.9
PARAMETER top_k 50
PARAMETER repeat_penalty 1.1

SYSTEM \"\"\"You are a wise spiritual teacher and guide, trained in various wisdom traditions. You offer compassionate guidance on meditation, consciousness, inner peace, and spiritual growth. Your responses are thoughtful, practical, and rooted in timeless wisdom while being accessible to modern seekers.\"\"\"
"""
    
    # Save Modelfile
    with open("Modelfile", 'w') as f:
        f.write(modelfile_content)
    
    logger.info(f"üìÑ Ollama Modelfile created: Modelfile")
    
    # Create instructions
    instructions = f"""
ü¶ô Ollama Setup Instructions
============================

1. Install Ollama (if not already installed):
   curl -fsSL https://ollama.ai/install.sh | sh

2. Create the model from Hugging Face:
   ollama create {model_name} -f Modelfile

3. Run your spiritual AI:
   ollama run {model_name}

4. Example usage:
   ollama run {model_name} "What is the nature of consciousness?"
   ollama run {model_name} "How can I find inner peace?"

Your enlightened AI is ready for local use! üßò‚Äç‚ôÇÔ∏è‚ú®
"""
    
    with open("OLLAMA_SETUP.md", 'w') as f:
        f.write(instructions)
    
    logger.info("üìã Ollama setup instructions saved to: OLLAMA_SETUP.md")
    
    return modelfile_content


def main():
    """Main upload function."""
    import argparse
    
    parser = argparse.ArgumentParser(description="Upload Spiritual AI to Hugging Face")
    parser.add_argument("--model-path", default="models/spiritual-wisdom-llama",
                       help="Path to the fine-tuned model")
    parser.add_argument("--repo-name", default="spiritual-wisdom-llama-3b",
                       help="Repository name on Hugging Face")
    parser.add_argument("--username", type=str,
                       help="Hugging Face username")
    parser.add_argument("--private", action="store_true",
                       help="Make repository private")
    parser.add_argument("--ollama-name", default="spiritual-ai",
                       help="Name for Ollama model")
    
    args = parser.parse_args()
    
    try:
        # Upload to Hugging Face
        repo_id = upload_model_to_hf(
            model_path=args.model_path,
            repo_name=args.repo_name,
            username=args.username,
            private=args.private
        )
        
        # Create Ollama files
        create_ollama_modelfile(repo_id, args.ollama_name)
        
        print("\nüéâ SUCCESS! Your spiritual AI is now available on Hugging Face!")
        print(f"üîó Model: https://huggingface.co/{repo_id}")
        print(f"ü¶ô Ollama setup: See OLLAMA_SETUP.md for instructions")
        
    except Exception as e:
        print(f"\n‚ùå Error: {e}")
        print("Make sure you're logged in to Hugging Face: huggingface-cli login")


if __name__ == "__main__":
    main() 